{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-21T14:57:14.024560Z",
     "start_time": "2019-04-21T14:56:59.370434Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Program Files (x86)\\Microsoft Visual Studio\\Shared\\Anaconda3_64\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.utils.data as Data\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T14:38:46.757321Z",
     "start_time": "2019-04-16T14:38:46.387262Z"
    }
   },
   "outputs": [],
   "source": [
    "class Dynamic_LSTM(nn.Module):\n",
    "    def __init__(self, n_actions, n_units, n_input, n_hidden, n_output, lamda, dropout=0.3):\n",
    "        super(Dynamic_LSTM, self).__init__()\n",
    "\n",
    "        # hyperparameters\n",
    "        self.n_actions = n_actions  # last K hidden state\n",
    "        self.n_units = n_units  # hidden unit of Agent MLP\n",
    "        self.n_input = n_input  # input size\n",
    "        self.n_hidden = n_hidden  # hidden size of LSTM\n",
    "        self.n_output = n_output  # output dim\n",
    "        self.lamda = lamda\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.agent_action = []\n",
    "        self.agent_prob = []\n",
    "\n",
    "        # layers\n",
    "        self.fc1 = nn.Linear(self.n_hidden + self.n_input, self.n_units)\n",
    "        self.fc2 = nn.Linear(self.n_units, self.n_actions)\n",
    "        self.x2h = nn.Linear(self.n_input, 4 * self.n_hidden)\n",
    "        self.h2h = nn.Linear(self.n_hidden, 4 * self.n_hidden)\n",
    "        self.output = nn.Linear(self.n_hidden, self.n_output)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.dropout = nn.Dropout(p=self.dropout)\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "    def choose_action(self, observation, cur_time):\n",
    "        observation = observation.detach()\n",
    "        result_fc1 = self.fc1(observation)\n",
    "        result_fc2 = self.fc2(result_fc1)\n",
    "        probs = self.softmax(result_fc2)\n",
    "        m = torch.distributions.Categorical(probs)\n",
    "        actions = m.sample()\n",
    "        if cur_time != 0:\n",
    "            self.agent_action.append(actions.unsqueeze(-1))\n",
    "            self.agent_prob.append(m.log_prob(actions))\n",
    "\n",
    "        return actions.unsqueeze(-1)\n",
    "\n",
    "    def forward(self, input):\n",
    "        # input shape [batch_size, timestep, feature_dim]\n",
    "        batch_size = input.size(0)\n",
    "        time_step = input.size(1)\n",
    "        feature_dim = input.size(2)\n",
    "        assert(feature_dim == self.n_input)\n",
    "\n",
    "        # Initialization\n",
    "        cur_time = 0  # Current timestep\n",
    "        self.agent_action = []  # Actions for agents\n",
    "        self.agent_prob = []  # Probabilities for agents\n",
    "        # Hidden state for lstm\n",
    "        cur_h = Variable(torch.zeros(batch_size, self.n_hidden))\n",
    "        # Cell memory for lstm\n",
    "        cur_c = Variable(torch.zeros(batch_size, self.n_hidden))\n",
    "        c = []  # Cell memory list for lstm\n",
    "        h = []  # Hidden state list for lstm\n",
    "\n",
    "        for cur_time in range(time_step):\n",
    "            if cur_time == 0:\n",
    "                self.choose_action(\n",
    "                    torch.cat((input[:, 0, :], cur_h), 1), cur_time)\n",
    "                observed_c = torch.zeros_like(cur_c, dtype=torch.float32).view(-1).repeat(\n",
    "                    self.n_actions).view(self.n_actions, batch_size, self.n_hidden)\n",
    "                observed_h = torch.zeros_like(cur_h, dtype=torch.float32).view(-1).repeat(\n",
    "                    self.n_actions).view(self.n_actions, batch_size, self.n_hidden)\n",
    "                action_c = cur_c\n",
    "                action_h = cur_h\n",
    "            else:\n",
    "                observed_c = torch.cat((observed_c[1:], cur_c.unsqueeze(0)), 0)\n",
    "                observed_h = torch.cat((observed_h[1:], cur_h.unsqueeze(0)), 0)\n",
    "                # use h(t-1) or mean h?\n",
    "                observation = torch.cat((input[:, cur_time, :], cur_h), 1)\n",
    "                actions = self.choose_action(observation, cur_time)\n",
    "                coord = torch.cat((actions.int(), torch.arange(\n",
    "                    batch_size, dtype=torch.int).unsqueeze(-1)), 1)\n",
    "                action_c = torch.stack([observed_c[i, j, :]\n",
    "                                        for [i, j] in coord])\n",
    "                action_h = torch.stack([observed_h[i, j, :]\n",
    "                                        for [i, j] in coord])\n",
    "            \n",
    "            weighted_c = self.lamda * action_c + (1-self.lamda)*cur_c\n",
    "            weighted_h = self.lamda * action_h + (1-self.lamda)*cur_h\n",
    "\n",
    "            gates = self.x2h(input[:, cur_time, :]) + self.h2h(weighted_h)\n",
    "            gates = gates.squeeze()\n",
    "\n",
    "            ingate, forgetgate, cellgate, outgate = gates.chunk(4, 1)\n",
    "\n",
    "            ingate = self.sigmoid(ingate)\n",
    "            forgetgate = self.sigmoid(forgetgate)\n",
    "            if self.dropout == 0:\n",
    "                cellgate = self.tanh(cellgate)\n",
    "            else:\n",
    "                cellgate = self.dropout(self.tanh(cellgate))\n",
    "            outgate = self.sigmoid(outgate)\n",
    "\n",
    "            cur_c = torch.mul(weighted_c, forgetgate) + \\\n",
    "                torch.mul(ingate, cellgate)\n",
    "            cur_h = torch.mul(outgate, self.tanh(cur_c))\n",
    "            c.append(cur_c)\n",
    "            h.append(cur_h)\n",
    "\n",
    "        opt = self.output(cur_h)\n",
    "        opt = self.softmax(opt)\n",
    "\n",
    "        return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T13:44:11.688304Z",
     "start_time": "2019-04-16T13:44:07.698994Z"
    }
   },
   "outputs": [],
   "source": [
    "all_train = []  # the first 10 numbers are inputs, the last one is label in each row\n",
    "all_test = []\n",
    "for _ in range(100000):\n",
    "    a = np.random.choice(10, 9)\n",
    "    b = np.random.choice(9, 1)\n",
    "    c = a[b]\n",
    "    train = np.append(np.append(a, b), c)\n",
    "    all_train.append(train)\n",
    "\n",
    "\n",
    "for _ in range(10000):\n",
    "    a = np.random.choice(10, 9)\n",
    "    b = np.random.choice(9, 1)\n",
    "    c = a[b]\n",
    "    test = np.append(np.append(a, b), c)\n",
    "    all_test.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T13:44:12.053441Z",
     "start_time": "2019-04-16T13:44:11.690292Z"
    }
   },
   "outputs": [],
   "source": [
    "onehot = torch.eye(10)\n",
    "all_train = onehot[all_train].numpy()\n",
    "all_test = onehot[all_test].numpy()\n",
    "\n",
    "train_data = all_train[:, :-1, :]\n",
    "train_label = all_train[:, -1, :]\n",
    "test_data = all_test[:, :-1, :]\n",
    "test_label = all_test[:, -1, :]\n",
    "\n",
    "train_dataset = Data.TensorDataset(torch.tensor(\n",
    "    train_data, dtype=torch.float32), torch.tensor(train_label, dtype=torch.float32))\n",
    "test_dataset = Data.TensorDataset(torch.tensor(\n",
    "    test_data, dtype=torch.float32), torch.tensor(test_label, dtype=torch.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-04-16T16:36:36.994123Z",
     "start_time": "2019-04-16T15:29:40.723542Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Dynamic_LSTM(n_actions=10, n_units=10, n_input=10,\n",
    "                     n_hidden=30, n_output=10, lamda=1, dropout=0)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=100)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=100)\n",
    "\n",
    "best_acc = 0\n",
    "train_loss = []\n",
    "count = 0\n",
    "\n",
    "for epoch in range(200):\n",
    "    print('****************  RL is beginning  *******************')\n",
    "    model.train()\n",
    "    cur_loss = []\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss_task = torch.mean(-torch.log(output+1e-7)*target)\n",
    "        correct_pred = torch.argmax(output, 1).eq(torch.argmax(target, 1))\n",
    "        accuracy = torch.mean(correct_pred.float())\n",
    "\n",
    "        act_prob = model.agent_prob\n",
    "        act_prob = torch.stack(act_prob).permute(1, 0)\n",
    "        acts = model.agent_action\n",
    "        acts = torch.squeeze(torch.stack(acts)).permute(1, 0)\n",
    "        #neg_log_prob = torch.sum(-torch.log(act_prob+0.000001) * onehot[acts], dim=2)\n",
    "        rewards = (correct_pred.float() - 0.5) * 2\n",
    "        rewards = rewards.unsqueeze(-1)\n",
    "        loss_RL = torch.mean(-act_prob * rewards)\n",
    "        loss_total = loss_task+loss_RL*0.3\n",
    "        cur_loss.append(loss_total.detach().numpy())\n",
    "        loss_total.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 200 == 0:\n",
    "            print('the %d epoch the %d time accuracy is %f, loss is %f' %\n",
    "                  (epoch, batch_idx, accuracy, loss_total))\n",
    "            print('loss_RL:', loss_RL.detach().numpy())\n",
    "            print('loss_Task:', loss_task.detach().numpy())\n",
    "            print(acts[:5,-1])\n",
    "            print(torch.argmax(target[:5], dim=1))\n",
    "            print()\n",
    "    train_loss.append(np.average(np.array(cur_loss)))\n",
    "\n",
    "    print('###############  TESTING  ####################')\n",
    "    model.eval()\n",
    "    test_loss = []\n",
    "    test_acc = []\n",
    "    for batch_idx, (data, target) in enumerate(test_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        output = model(data)\n",
    "        loss_task = torch.mean(-torch.log(output+1e-7)*target)\n",
    "        correct_pred = torch.argmax(output, 1).eq(torch.argmax(target, 1))\n",
    "        accuracy = torch.mean(correct_pred.float())\n",
    "\n",
    "        act_prob = model.agent_prob\n",
    "        acts = model.agent_action\n",
    "        acts = torch.squeeze(torch.stack(acts)).permute(1, 0)\n",
    "        \n",
    "        act_prob = torch.stack(act_prob).permute(1, 0)\n",
    "        rewards = (correct_pred.float() - 0.5) * 2\n",
    "        rewards = rewards.unsqueeze(-1)\n",
    "        loss_RL = torch.mean(act_prob * rewards)\n",
    "        loss_total = loss_task+loss_RL\n",
    "\n",
    "        test_loss.append(loss_total)\n",
    "        test_acc.append(accuracy)\n",
    "    print('the TEST accuracy is %f, loss is %f' %\n",
    "          (sum(test_acc)/len(test_acc), sum(test_loss)/len(test_loss)))\n",
    "\n",
    "    cur_acc = sum(test_acc)/len(test_acc)\n",
    "    if cur_acc > best_acc:\n",
    "        best_acc = cur_acc\n",
    "        print('===============================================>>>> SAVE MODEL')\n",
    "        count = 0\n",
    "    count += 1\n",
    "    if count == 5:\n",
    "        print('--------------------------------------------->>>>  EARLY STOP!!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
